name: Scrape Website and Twilio Send
on:
  workflow_dispatch: # allows you to manually trigger the workflow
env:
  TWILIO_ACCOUNT_SID: ${{ secrets.TWILIO_ACCOUNT_SID }}
  TWILIO_API_KEY: ${{ secrets.TWILIO_API_KEY }}
  TWILIO_API_SECRET: ${{ secrets.TWILIO_API_SECRET }}
  URL: ${{ secrets.URL }}
  TEXT_TO_FIND: ${{ secrets.TEXT_TO_FIND }}
permissions:
  contents: read

jobs:
  scrape:
    runs-on: ubuntu-latest
    steps:
      - name: Set up Python environment
        run: |
          python3 -m venv venv
          source venv/bin/activate
          pip install requests beautifulsoup4

      - name: Scrape the website
        id: scrape_step
        run: |
          source venv/bin/activate
          python3 - <<EOF
          import requests
          from bs4 import BeautifulSoup
          from requests.adapters import HTTPAdapter
          from urllib3.util.retry import Retry
      
          # Set up a retry strategy
          retry_strategy = Retry(
              total=5,  # Retry 5 times
              status_forcelist=[429, 500, 502, 503, 504],  # Retry on these HTTP statuses
              method_whitelist=["HEAD", "GET", "OPTIONS"],  # Retry only on these HTTP methods
              backoff_factor=1  # Wait 1, 2, 4, 8, etc. seconds between retries
          )
          adapter = HTTPAdapter(max_retries=retry_strategy)
          http = requests.Session()
          http.mount("https://", adapter)
          http.mount("http://", adapter)
      
          # Fetch the page content
          url = "${{ secrets.URL }}"
          text_to_find = "${{ secrets.TEXT_TO_FIND }}"
      
          try:
              response = http.get(url)
              response.raise_for_status()  # Raise an error for bad HTTP statuses
              page_content = response.text
              soup = BeautifulSoup(page_content, 'html.parser')
      
              # Check if the text exists in the content
              if text_to_find in soup.get_text():
                  print(f"::set-output name=text_found::true")
              else:
                  print(f"::set-output name=text_found::false")
      
          except requests.exceptions.RequestException as e:
              print(f"::error ::Failed to fetch the website: {e}")
          EOF
    outputs:
      text_found: ${{ steps.scrape_step.outputs.text_found }}

  send:
    needs: scrape
    if: needs.scrape.outputs.text_found == 'false'  # Only run if text was not found
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - uses: fabasoad/twilio-voice-call-action@v1
        with:
          text: 'GitHub actions build number ${{ github.run_number }} passed successfully.'
          from: ${{ secrets.FROM_PHONE }}
          to: ${{ secrets.TO_PHONE }}
          twilio_account_sid: ${{ secrets.TWILIO_ACCOUNT_SID }}
          twilio_auth_token: ${{ secrets.TWILIO_AUTH_TOKEN }}
